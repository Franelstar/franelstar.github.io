---
permalink: /projects/
title: "Projects"
author_profile: true
---

<section>

    <div class="experience-entry">
        <h3 style="font-weight: bold;">Project – Building a CI/CD Pipeline in an MLOps Context</h3>
        <div class="content_exp">
          <div><em>(June 2025)</em></div>
      
          <div>
            As part of a lab project, I designed and implemented a <strong>Continuous Integration (CI)</strong> and <strong>Continuous Deployment (CD)</strong> solution for a Python command-line application. The primary goal was to automate key software quality processes essential to MLOps, including linting, formatting, refactoring, and testing.
            <br><br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/CI-CD-Lab" target="_blank">Franelstar/CI-CD-Lab</a>
          </div>
      
          <div style="margin-top: 15px;"><strong>Skills:</strong> 
            <em class="skill">MLOps</em> 
            <em class="skill">CI/CD</em> 
            <em class="skill">Software Quality Automation</em> 
            <em class="skill">Python</em> 
            <em class="skill">Testing</em> 
            <em class="skill">Linting</em> 
            <em class="skill">Refactoring</em> 
            <em class="skill">GitHub Actions</em>
          </div>
        </div>
      </div>
    
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">Project – Face Anti-Spoofing and Facial Recognition</h3>
        <div class="content_exp">
          <div><strong>Vietnam National University, Hanoi</strong> <em>(March 2021 – April 2021)</em></div>
      
          <div>
            This project focused on developing a robust facial recognition system enhanced with anti-spoofing mechanisms to detect and prevent identity fraud, such as attempts using printed photos, videos, or masks during authentication.
            <br><br>
            <strong>Objectives:</strong>
            <ul>
              <li>Build an accurate and fast facial recognition model</li>
              <li>Integrate anti-spoofing techniques to distinguish real faces from spoofing attempts</li>
              <li>Ensure system reliability under various lighting conditions, angles, and image quality</li>
            </ul>
      
            <strong>Technologies and tools used:</strong>
            <ul>
              <li>Deep Learning (Convolutional Neural Networks – CNNs)</li>
              <li>Anti-spoofing algorithms based on texture analysis, motion detection, and 3D facial features</li>
              <li>Python libraries: <code>OpenCV</code>, <code>Dlib</code>, <code>TensorFlow</code>, <code>PyTorch</code></li>
            </ul>
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/Visage_antispoofing_recognition" target="_blank">Franelstar/Visage_antispoofing_recognition</a>
          </div>
      
          <div style="margin-top: 15px;"><strong>Skills:</strong> 
            <em class="skill">Computer Vision</em> 
            <em class="skill">Facial Recognition</em> 
            <em class="skill">Anti-Spoofing</em> 
            <em class="skill">Deep Learning</em> 
            <em class="skill">CNN</em> 
            <em class="skill">OpenCV</em> 
            <em class="skill">Python</em> 
            <em class="skill">TensorFlow</em> 
            <em class="skill">PyTorch</em> 
            <em class="skill">Dlib</em>
          </div>
        </div>
      </div>

      <div class="experience-entry">
        <h3 style="font-weight: bold;">Project – Creating a Magic Book in Virtual and Augmented Reality</h3>
        <div class="content_exp">
          <div><em>(March 2021)</em></div>
      
          <div>
            This project aimed to design and develop an interactive "magic book" experience using virtual reality (VR) and augmented reality (AR) technologies to bring stories and illustrations to life.
            <br><br>
            <strong>Objectives:</strong>
            <ul>
              <li>Create immersive content combining 3D models, animations, and interactive elements triggered by the physical pages of the book</li>
              <li>Use augmented reality to overlay digital content on physical pages via a smartphone or tablet camera</li>
              <li>Implement VR-based scenarios that allow users to fully explore the book's universe in an immersive environment</li>
            </ul>
      
            <strong>Technologies and tools:</strong>
            <ul>
              <li><strong>Unity 3D</strong> for VR/AR development</li>
              <li><strong>ARKit</strong> / <strong>ARCore</strong> for augmented reality features</li>
              <li><strong>Python</strong> for scripting and logic</li>
            </ul>
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/Magic-Book-AR" target="_blank">Franelstar/Magic-Book-AR</a>
          </div>
      
          <div style="margin-top: 15px;"><strong>Skills:</strong> 
            <em class="skill">Virtual Reality (VR)</em> 
            <em class="skill">Augmented Reality (AR)</em> 
            <em class="skill">Unity 3D</em> 
            <em class="skill">ARKit</em> 
            <em class="skill">ARCore</em> 
            <em class="skill">3D Modeling</em> 
            <em class="skill">Animation</em> 
            <em class="skill">Python</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Fake News Detection, Sentiment Analysis on COVID-19 Tweets, and South Park Dialogue Recognition using Natural Language Processing (NLP)
        </h3>
        <div class="content_exp">
          <div><em>(March 2021)</em></div>
      
          <div>
            This project combines several NLP applications aiming to analyze, classify, and extract information from texts from various sources.
      
            <br><br><strong>Objectives:</strong>
            <ul>
              <li>Detect fake news from texts using supervised classification techniques (TF-IDF, SVM, etc.)</li>
              <li>Perform sentiment analysis on coronavirus-related tweets to identify dominant emotions (positive, negative, neutral)</li>
              <li>Recognize South Park characters from their dialogues using text classification models</li>
            </ul>
      
            <strong>Technologies and Tools:</strong>
            <ul>
              <li>Python, NLTK, Scikit-learn, Pandas, NumPy</li>
              <li>Vector representations: Bag of Words, TF-IDF</li>
              <li>Classification models: SVM, Naive Bayes, Logistic Regression</li>
              <li>Preprocessing: tokenization, lemmatization, text cleaning</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/text-classification" target="_blank">Franelstar/text-classification</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Python</em>
            <em class="skill">Docker</em>
            <em class="skill">Scikit-learn</em>
            <em class="skill">NumPy</em>
            <em class="skill">Pandas</em>
            <em class="skill">Natural Language Processing (NLP)</em>
          </div>
        </div>
      </div>

      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Optical Flow Estimation and Object Segmentation by Velocity
        </h3>
        <div class="content_exp">
          <div><em>(March 2021)</em></div>
      
          <div>
            This project aims to leverage optical flow to estimate movements in a sequence of images and automatically segment objects based on their velocity.
      
            <br><br><strong>Objectives:</strong>
            <ul>
              <li>Calculate optical flow between successive frames of a video to detect pixel-level movements</li>
              <li>Identify and segment moving objects by discriminating relative speeds (slow, fast, stationary)</li>
              <li>Analyze dynamic scenes to extract information on trajectories and visual behaviors</li>
            </ul>
      
            <strong>Methods and Tools:</strong>
            <ul>
              <li>Optical flow algorithms (Lucas-Kanade, Horn-Schunck, Farnebäck, etc.)</li>
              <li>Image processing and segmentation</li>
              <li>Motion vector visualization</li>
              <li>Python and OpenCV</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/optical_flow_segmentation" target="_blank">Franelstar/optical_flow_segmentation</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">OpenCV</em> 
            <em class="skill">Python</em>
            <em class="skill">Computer Vision</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Leaf Recognition for Plant Classification Using Bag of Words (BoW) Model
        </h3>
        <div class="content_exp">
          <div><em>(January 2021)</em></div>
      
          <div>
            This project aimed to develop a computer vision system capable of classifying plant species based on leaf images using a Bag of Words (BoW) visual model approach.
      
            <br><br><strong>Objectives:</strong>
            <ul>
              <li>Extract local features from leaf images (e.g., SIFT, ORB)</li>
              <li>Build a visual vocabulary by clustering descriptors using k-means</li>
              <li>Represent each image as a histogram of visual words</li>
              <li>Train a classifier (e.g., SVM) on these representations to predict plant species</li>
            </ul>
      
            <strong>Technologies and Methods:</strong>
            <ul>
              <li>Python, OpenCV for image processing and feature extraction</li>
              <li>Scikit-learn for clustering and classification</li>
              <li>Use of BoW model for visual representation</li>
              <li>Dataset preparation and performance evaluation (cross-validation, accuracy metrics)</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/Leaf-recognition-for-plant-classification-using-the-Bag-of-Words-model" target="_blank">Franelstar/Leaf-recognition-for-plant-classification-using-the-Bag-of-Words-model</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">OpenCV</em> 
            <em class="skill">Python</em> 
            <em class="skill">Scikit-learn</em>
          </div>
        </div>
      </div>

      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Object Recognition Using the SIFT Descriptor
        </h3>
        <div class="content_exp">
          <div><em>(December 2020)</em></div>
      
          <div>
            This project involved developing an application capable of automatically detecting and recognizing an object in an image using keypoints and local descriptors extracted by the SIFT (Scale-Invariant Feature Transform) algorithm.
      
            <br><br><strong>Objectives:</strong>
            <ul>
              <li>Detect interest points characteristic of an object</li>
              <li>Extract descriptors invariant to scale, rotation, and illumination</li>
              <li>Perform matching between descriptors of the target object and those of a scene</li>
              <li>Identify the presence and position of the recognized object</li>
            </ul>
      
            <strong>Technologies and Tools:</strong>
            <ul>
              <li>Python with OpenCV (SIFT, FLANN, BFMatcher)</li>
              <li>Image processing and computer vision</li>
              <li>Descriptor matching and homography estimation</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/Reconnaissance_objets_SIFT" target="_blank">Franelstar/Reconnaissance_objets_SIFT</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Computer Vision</em> 
            <em class="skill">OpenCV</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Skin Pixel Detection Based on Color
        </h3>
        <div class="content_exp">
          <div><em>(November 2020)</em></div>
      
          <div>
            This project aimed to detect regions corresponding to human skin in an image by exploiting colorimetric information from different color spaces.
      
            <br><br><strong>Objectives:</strong>
            <ul>
              <li>Identify pixels corresponding to skin based on their color values</li>
              <li>Compare the performance of different color spaces (RGB, HSV, YCrCb, etc.)</li>
              <li>Obtain a binary mask locating skin areas in an image</li>
            </ul>
      
            <strong>Methodology:</strong>
            <ul>
              <li>Transform images into different color spaces</li>
              <li>Define value ranges (thresholding) associated with skin</li>
              <li>Apply morphological filters to clean the masks</li>
              <li>Visualize results (segmentation, contours)</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>  
            <a href="https://github.com/Franelstar/Skin-detection" target="_blank">Franelstar/Skin-detection</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">OpenCV</em> 
            <em class="skill">Python</em> 
            <em class="skill">Computer Vision</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Explainability Analysis of Classification Models with LIME
        </h3>
        <div class="content_exp">
          <div><em>(October 2020)</em></div>
          <div><em>Associated with Vietnam National University, Hanoi</em></div>
      
          <div>
            This project studied the interpretability of machine learning models through the LIME method (Local Interpretable Model-agnostic Explanations), applied to two concrete cases:
            <ol>
              <li>Image recognition (dogs vs cats) using a convolutional neural network (CNN)</li>
              <li>Breast cancer prediction using an SVM classifier (presence or absence)</li>
            </ol>
      
            <strong>Objectives:</strong>
            <ul>
              <li>Understand local model behavior by explaining their predictions</li>
              <li>Visualize important regions in an image for CNN</li>
              <li>Identify influential medical features for SVM</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/explainable-Artificial-Intelligence" target="_blank">Franelstar/explainable-Artificial-Intelligence</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Python</em> 
            <em class="skill">TensorFlow</em> 
            <em class="skill">Sklearn</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Object and Person Tracking in Video (OpenCV, Dlib)
        </h3>
        <div class="content_exp">
          <div><em>(October 2020)</em></div>
      
          <div>
            This project involved developing a real-time visual tracking system for objects or people in video, combining object detection and color-based tracking.
            <br>
            <br>
            <strong>Implemented approach:</strong>
            <ul>
              <li>Use of Dlib for initial object/person detection in images (HOG + SVM)</li>
              <li>Implementation of a color-based tracking algorithm (HSV space segmentation, thresholds, masking)</li>
              <li>Use of OpenCV for image processing: detection, bounding box drawing, trajectory calculation</li>
              <li>Robust tracking in video sequences, even with fast movements or scale changes</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/video-object-tracking" target="_blank">Franelstar/video-object-tracking</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Python</em> 
            <em class="skill">OpenCV</em>
            <em class="skill">Dlib</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          TPE – Video Research Backend
        </h3>
        <div class="content_exp">
          <div><em>(Dec. 2019 – Sept. 2020)</em></div>
      
          <div>
            In the context of a year-long supervised personal project (TPE), I developed a content-based video search application. This project aims to automatically analyze videos to extract structured information that facilitates search and exploitation.
            <br>
            <br>
            <strong>Main features:</strong>
            <ul>
              <li>Automatic video segmentation into distinct scenes</li>
              <li>Scene type classification (bedroom, living room, etc.)</li>
              <li>Detection and identification of objects present in each scene</li>
              <li>Counting the number of people per scene with result storage</li>
              <li>The application uses an API enabling search based on extracted metadata. A client application is used to perform these searches.</li>
            </ul>
            
            <strong>Technologies used:</strong>
            <ul>
              <li>Language: Python</li>
              <li>Libraries: TensorFlow, Flask, OpenCV, dlib, face_recognition, moviepy, scenedetect, numpy, matplotlib, PILLOW</li>
              <li>Database: PostgreSQL</li>
              <li>Deep scene detection models</li>
            </ul>
      
            This project allowed me to apply advanced techniques in computer vision, facial recognition, and video processing, while developing a complete tool for content-based video search.
            <br>
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/TPE_Video_Research_Backend" target="_blank">Franelstar/TPE_Video_Research_Backend</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Computer vision</em> 
            <em class="skill">Machine learning</em> 
            <em class="skill">Deep learning</em> 
            <em class="skill">Docker</em>
            <em class="skill">User Interface (UI)</em> 
            <em class="skill">Python</em> 
            <em class="skill">OpenCV</em> 
            <em class="skill">TensorFlow</em>
            <em class="skill">numpy</em>
            <em class="skill">matplotlib</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Academic Project – Creation of an Ontology on the Family Theme (RDF, RDFS, OWL, Protégé)
        </h3>
        <div class="content_exp">
          <div><em>(Jul. 2020)</em></div>
      
          <div>
            As part of a semantic web project, I designed an ontology modeling family relationships using standard Semantic Web technologies such as RDF, RDFS, and OWL, with the Protégé tool.
            <br>
            <br>
            <strong>Project Objectives:</strong>
            <ul>
              <li>Formally represent concepts related to family (person, parent, child, marriage, etc.)</li>
              <li>Define relationships between individuals (parentage, siblinghood, marriage)</li>
              <li>Implement logical rules for automatic inference of new facts (e.g., if A is parent of B and B is parent of C, then A is grandparent of C)</li>
              <li>Verify ontology consistency using reasoning engines</li>
            </ul>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Knowledge Graphs</em> 
            <em class="skill">Semantic Web</em> 
            <em class="skill">RDF / RDFS</em> 
            <em class="skill">OWL</em> 
            <em class="skill">Protégé</em> 
            <em class="skill">Ontologies</em> 
            <em class="skill">Description Logic</em> 
            <em class="skill">Automated Reasoning</em> 
            <em class="skill">Semantic Modeling</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Data Analysis and Machine Learning with Python (scikit-learn, pandas, seaborn, matplotlib)
        </h3>
        <div class="content_exp">
          <div><em>(March 2020 – July 2020)</em></div>
      
          <div>
            In this project, I implemented a complete data processing and analysis pipeline in Python, from exploratory data analysis to predictive modeling.
            <br>
            <br>
            <strong>Objectives:</strong>
            <ul>
              <li>Perform descriptive and exploratory data analysis (statistics, visualizations)</li>
              <li>Apply unsupervised learning techniques (factor analysis, clustering)</li>
              <li>Use supervised learning algorithms for classification and regression (SVM, KNN, decision trees, linear regression)</li>
              <li>Develop a predictive model for house prices</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/Data_scientist_house_data" target="_blank">Franelstar/Data_scientist_house_data</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">Python</em> 
            <em class="skill">scikit-learn</em> 
            <em class="skill">pandas</em> 
            <em class="skill">seaborn</em> 
            <em class="skill">matplotlib</em> 
            <em class="skill">Data Analysis</em> 
            <em class="skill">Machine Learning</em>
            <em class="skill">Predictive Modeling</em> 
            <em class="skill">Data Visualization</em>
          </div>
        </div>
      </div>

      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Project – Intelligent Agents for Item Delivery Simulation (JADE, GAIA, FIPA-ACL)
        </h3>
        <div class="content_exp">
          <div><em>(May 2020)</em></div>
      
          <div>
            In this project, I designed a simulation of an autonomous delivery system based on intelligent agents, leveraging the JADE platform and FIPA-ACL communication standards. The goal was to model a network of agents (clients, warehouses, couriers) capable of cooperating to efficiently deliver packages in a dynamic environment.
            <br><br>
            <strong>Main features:</strong>
            <ul>
              <li>Modeling autonomous agents with defined roles (client, carrier, manager)</li>
              <li>Inter-agent communication following FIPA-ACL standards</li>
              <li>Use of GAIA methodology for role and interaction design</li>
              <li>Negotiation, task allocation, and delivery planning</li>
              <li>Responsiveness to environmental changes (delays, failures, new orders)</li>
            </ul>
      
            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/Projet-Jade" target="_blank">Franelstar/Projet-Jade</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong> 
            <em class="skill">JADE</em> 
            <em class="skill">FIPA-ACL</em> 
            <em class="skill">GAIA</em> 
            <em class="skill">Multi-agent Systems</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Academic Project – Image Processing Application in Python
        </h3>
        <div class="content_exp">
          <div><em>(April 2020)</em></div>
      
          <div>
            Developed an image processing tool integrating manual implementation and experimentation of many fundamental algorithms. The goal was to gain a deep understanding of image transformation, filtering, edge detection, and frequency analysis mechanisms.
            <br><br>
            <strong>Implemented algorithms:</strong>
            <ul>
              <li><strong>Image enhancement:</strong>
                <ul>
                  <li>Histogram, linear transformation, gamma correction</li>
                  <li>Histogram equalization</li>
                </ul>
              </li>
              <li><strong>Smoothing filters:</strong>
                <ul>
                  <li>Mean filter, median filter, Gaussian filter, convolution</li>
                </ul>
              </li>
              <li><strong>Edge detection:</strong>
                <ul>
                  <li>Prewitt, Roberts, Sobel, Laplacian, Canny</li>
                </ul>
              </li>
              <li><strong>Mathematical morphology:</strong>
                <ul>
                  <li>Opening, closing, binary image processing</li>
                </ul>
              </li>
              <li><strong>Frequency analysis:</strong>
                <ul>
                  <li>Fourier transform</li>
                </ul>
              </li>
              <li><strong>Color space manipulation:</strong>
                <ul>
                  <li>Conversion RGB ↔ grayscale, binary, HSV, etc.</li>
                </ul>
              </li>
            </ul>

            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/taitementImage" target="_blank">Franelstar/taitementImage</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong>
            <em class="skill">Python</em>
            <em class="skill">NumPy</em>
            <em class="skill">OpenCV</em>
            <em class="skill">Computer Vision</em>
          </div>
        </div>
      </div>
      
      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Simulation Project – Spread of a Contagious Disease and Social Distancing Effects (GAMA Platform)
        </h3>
        <div class="content_exp">
          <div><em>(April 2020)</em></div>
      
          <div>
            As part of a multi-agent modeling project, I developed a simulation of the spread of a contagious disease within a city using the GAMA platform. The aim was to analyze the impact of different social distancing policies on the epidemic dynamics.
            <br><br>
            <strong>Project objectives:</strong>
            <ul>
              <li>Model a population of mobile agents with daily behaviors (movement, interaction, infection)</li>
              <li>Simulate virus transmission based on epidemiological parameters (contamination rate, incubation, recovery)</li>
              <li>Study the effects of health measures: lockdown, mobility reduction, mask-wearing, etc.</li>
              <li>Visualize the epidemic evolution according to applied strategies</li>
            </ul>

            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/TP-SMA" target="_blank">Franelstar/TP-SMA</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong>
            <em class="skill">GAMA</em>
            <em class="skill">GALM</em>
            <em class="skill">Multi-Agent Programming</em>
          </div>
        </div>
      </div>

      <div class="experience-entry">
        <h3 style="font-weight: bold;">
          Academic Project – Java Application for Graph Algorithm Visualization
        </h3>
        <div class="content_exp">
          <div><em>(December 2019 – March 2020)</em></div>
      
          <div>
            As part of a university project, I designed and developed a Java application to visualize and execute various fundamental graph theory algorithms. The project integrates Graphviz and the DOT language to dynamically represent graphs, providing an interactive interface focused on learning and experimentation.
            <br><br>
            <strong>Key features:</strong>
            <ul>
              <li>Step-by-step visualization and execution of several algorithms:</li>
              <ul>
                <li>Depth-first search (DFS) and breadth-first search (BFS)</li>
                <li>Shortest path algorithms: Dijkstra, Bellman-Ford</li>
                <li>Minimum spanning tree algorithms: Prim, Kruskal</li>
                <li>Maximum flow algorithm: Ford-Fulkerson</li>
              </ul>
              <li>Graphical user interface developed in Java (Swing/JavaFX)</li>
              <li>Graph export and rendering using Graphviz (.dot files)</li>
            </ul>

            <br>
            <i class="fab fa-github" aria-hidden="true"></i> <strong>GitHub repository:</strong>
            <a href="https://github.com/Franelstar/RO-IHM" target="_blank">Franelstar/RO-IHM</a>
          </div>
      
          <div style="margin-top: 15px;">
            <strong>Skills:</strong>
            <em class="skill">Graphviz</em>
            <em class="skill">Java</em>
            <em class="skill">GUI</em>
            <em class="skill">Graph Theory</em>
          </div>
        </div>
      </div>
      
      
</section>